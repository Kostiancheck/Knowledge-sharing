# ElasticSearch

Created: March 23, 2024 5:22 PM
Owner: Din Lester
Tags: databases, search engine
Status: Done

Elasticsearch is a powerful, open-source, distributed search and analytics engine. It's widely used for its speed, scalability, and ease of integration with a variety of applications. Here are some key aspects of Elasticsearch:

1. **Full-Text Search Capabilities**: Elasticsearch is particularly well-known for its full-text search capabilities. It allows for complex search queries and efficient searching through large volumes of text.
2. **Real-Time Data and Analytics**: It processes real-time data and provides analytics in real-time. This feature is highly beneficial for applications that require instantaneous responses, such as log and event data analysis.
3. **Distributed Nature**: Elasticsearch stores data in a distributed manner, which helps in managing large datasets and high throughput. This also ensures high availability and resilience.
4. **Scalability**: One of the primary advantages of Elasticsearch is its ability to scale out to hundreds of servers and handle petabytes of data.
5. **Restful API**: Elasticsearch can be interacted with using a RESTful API, making it easy to integrate with many programming languages.
6. **Document-Oriented**: Instead of storing data in tables and rows (as in traditional relational databases), Elasticsearch stores complex data structures serialized as JSON documents.
7. **Lucene Based**: Elasticsearch is built on top of Lucene, a highly performant text search engine library. This foundation provides Elasticsearch with robust search capabilities.
8. **Use Cases**: Common use cases for Elasticsearch include log and event data analysis, full-text search, security intelligence, business analytics, and operational intelligence.
9. **Elastic Stack Integration**: Often used in conjunction with other components of the Elastic Stack (formerly known as ELK Stack), including Logstash (for data processing and ingestion) and Kibana (for data visualization).

## Elastic Stack

![Untitled](ElasticSearch%2071c605a4814949d79d71ddd4be1b4c8b/Untitled.png)

### Logstash is a data processing pipeline

![Untitled](ElasticSearch%2071c605a4814949d79d71ddd4be1b4c8b/Untitled%201.png)

It consists of 3 parts: inputs, filters and outputs. Basically, it retrievies info from input plugins processes it with some rules and pushes somwhere( stashes ). You can have multiple piplenes running within 1 logstash.

**Example of logstash pipeline:**

![Untitled](ElasticSearch%2071c605a4814949d79d71ddd4be1b4c8b/Untitled%202.png)

**Grok patterns** is used to parse input info, similar to regular expressions

For example, we want to parse this string:

```python
# INPUT STRING
55.3.244.1 GET /index.html 15824 0.043

input {
      file {
        path => "/var/log/http.log"
      }
    }
    filter {
      grok {
        match => { "message" => "%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}" }
      }
    }
```

![Untitled](ElasticSearch%2071c605a4814949d79d71ddd4be1b4c8b/Untitled%203.png)

### X-PACK

This app provides additional functionality for ES, such as:

- Security, authorizations and authentication, adds LDAP, ActiveDirectory, OAuth for authentications and RBAC for authorization
- Monitor, helps to monitor ELK stack, Disk, CPU and memory usage, set up alerting and notifying (Email, Slack, etc) if something is happening
- Reporting, allows to download PDFs of kibana dashoards, they can be autogenerated and sended via email. They also can triggered on specific conditions
- ML, can analyze Kibana vizualisations and detect anomalies
- Graph, helps us find related data, e.g. suggest a user similar products or whatever
- SQL, query ES with SQL

### BEATS

It is a collection, called a data shippers. They are used to send data from various sources to Elasticsearch or Logstash. Each Beat is designed to handle a specific type of data or use case, making them efficient and easy to use. 

Some beats:

- **Filebeat**: For forwarding and centralizing log files.
- **Metricbeat**: For collecting metrics from your systems and services.
- **Packetbeat**: For monitoring network traffic.
- **Winlogbeat**: For shipping Windows event logs.
- **Auditbeat**: For auditing the activities of users and processes on your system.
- **Heartbeat**: For monitoring the availability of services via periodic checks.

### Basic diagram of ELK

![Untitled](ElasticSearch%2071c605a4814949d79d71ddd4be1b4c8b/Untitled%204.png)

## Common architecture

Suppose, we have an E-commerce application. Of course, we start with few things: app, DB and frontend. Time goes, and we need to add new feature - search. As we know `LIKE %` in relational DBs is working slowly, so we need to add ES to our stack.

![Untitled](ElasticSearch%2071c605a4814949d79d71ddd4be1b4c8b/Untitled%205.png)

For this architecture, we need to add functionality for updating data in DB and ES. If we already have data in DB, just write script for migration.

Next, weâ€™re asked to have dasboards of some metrics, like orders, etc.

![Untitled](ElasticSearch%2071c605a4814949d79d71ddd4be1b4c8b/Untitled%206.png)

Suppose, our business if growing fast, and we need to know when to add more resources to our app. Just add **Metricbeat** and also **Filebeat** for see logs of application.

![Untitled](ElasticSearch%2071c605a4814949d79d71ddd4be1b4c8b/Untitled%207.png)

So far, so good, but suppose we need to somehow process logs, we can do this in application or use Logstash. Also, I forgot to mention that we using Ingest nodes in ES, they are used to preprocess documents before indexing, so itâ€™ll be better to delegacy this to Logstash

![Untitled](ElasticSearch%2071c605a4814949d79d71ddd4be1b4c8b/Untitled%208.png)

So, now event processing is centralized ðŸ™‚

## Basic architecture of ElasticSearch

When we run ElasticSearch, we basically starts a Node. This way, we can store a hundredes of terrabytes of data accross many machines, even though we have only hundreds of GBs per machine.

But how the data is distributed accross Nodes and how ES knows where the given data is stored ?

Basically, each node belongs to a cluster

![Untitled](ElasticSearch%2071c605a4814949d79d71ddd4be1b4c8b/Untitled%209.png)

In Nodes we stores **documents**

![Untitled](ElasticSearch%2071c605a4814949d79d71ddd4be1b4c8b/Untitled%2010.png)

And **documents** is stored in **indices**

![Untitled](ElasticSearch%2071c605a4814949d79d71ddd4be1b4c8b/Untitled%2011.png)

## Sharding and availability

Sharding is a way to devide indicies into smaller picies and each piece is a shard. It is done at the index level, not at a cluster level.

Suppose, we have a big index 600GB and 2 nodes 500 GB per each, we cannot store this index in single shard and create 2

![Untitled](ElasticSearch%2071c605a4814949d79d71ddd4be1b4c8b/Untitled%2012.png)

Each shard is actually a **Apache Lucene** index. Shard can store up to about 2 billion documents

**Why to shard ?**

- Mainly to store more documents ðŸ˜‰
- Improved perfomance, parallelization of queries

An index containes a single shard by default

## Replication

Replication is supported natively and enabled by default

**How does it work ?**

- Replication is configured at the index level
- Creating copies of shards, reffered to as `replica shargs`
- Shard that has been replicated is called a `primary shard`
- A primary shard and its replica shards - replication group
- Replica shard can serve search requests, like primary shard do
- The number of replicas can be configured at index creation

![Untitled](ElasticSearch%2071c605a4814949d79d71ddd4be1b4c8b/Untitled%2013.png)

Replica shards are never stored on the same Node where primary shard is stored

## Snapshots

 We can use snpashots for backups

Suppose we need to do smth on the production index and it goes wrong, we cannot restore from the replication, because it is broken too, so use snapshots

![Untitled](ElasticSearch%2071c605a4814949d79d71ddd4be1b4c8b/Untitled%2014.png)