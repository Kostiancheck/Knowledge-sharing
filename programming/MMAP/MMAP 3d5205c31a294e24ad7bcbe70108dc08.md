# MMAP

Created: April 28, 2024 6:30 PM
Owner: Din Lester
Tags: OS, data structures, python
Status: Upcoming

### RESOURCES

- [https://mecha-mind.medium.com/understanding-when-and-how-to-use-memory-mapped-files-b94707df30e9](https://mecha-mind.medium.com/understanding-when-and-how-to-use-memory-mapped-files-b94707df30e9)
- [https://habr.com/ru/articles/55716/](https://habr.com/ru/articles/55716/)
- [https://youtu.be/nPIhoJ6lKeQ?si=4ZsJXbY3Sz3m3kTz](https://youtu.be/nPIhoJ6lKeQ?si=4ZsJXbY3Sz3m3kTz)

### **Understanding Memory Mapped Files**

In our lecture, the term **memory** refers to [random-access memory](https://en.wikipedia.org/wiki/Random-access_memory), or RAM.

There are several types of computer memory:

1. Physical
2. Virtual
3. Shared

In a standard file I/O operation, when we issue a read(bytes) command, the OS would **fetch the bytes from the file in disk**, then **cache the data in kernel space buffer** and then **make a copy of the cached data in the user space** (application’s address space).

> *The bytes are fetched as “**pages**” (usually **4KB**).*
> 

> *The information about the “pages” is maintained in a data structure called the “**page table**”.*
> 

Since a file might be arbitrarily large in size, when a request is sent to fetch a page, if the page is not found in page table, “**page fault**” occurs and the page is fetched from the disk and added to kernel buffer, copied to application buffer and updated in page table.

![Untitled](MMAP%203d5205c31a294e24ad7bcbe70108dc08/Untitled.png)

> *One of the advantage with this approach is that pages already in the “page table” can be read **without going to the disk**.*
> 

As we can see, when we use `read()` , under the hood our information is copied several times.

Basically, we can say that next steps are taking place:

1. **Disk Read Operations**: The hard drive's read/write head locates the data on the disk. This is a slow operation relative to other computing tasks because it involves physical movement and disk rotation.
2. **Direct Memory Access (DMA)**: Most modern systems use DMA for transferring data directly from the disk to physical memory without constant CPU intervention. This process is more efficient because it allows the CPU to perform other tasks while the data transfer occurs.
3.  **Memory Mapping**: Operating systems use a memory management scheme called virtual memory, allowing the separation of physical memory (RAM) from logical memory (addresses used by programs). Each program operates with its own set of addresses, which are mapped to physical memory addresses through a page table.
4. [OPTIONAL] **Demand Paging**: When a program accesses a part of the file, the corresponding page of that file might not initially be in RAM. The OS brings that page into RAM from the disk when needed, a process known as demand paging. If the page is already in RAM due to recent use (cached), the read operation is much faster.
5. **System Calls like `read()`**: Once the data is in the kernel's buffer, it can be copied to the user space buffer allocated by the application. This copying is done by system calls like **`read()`** in UNIX/Linux, which transfer data from the kernel buffer to the user buffer. This is necessary because user applications do not have direct access to kernel space for security and stability reasons.
6. **Buffer Management**: The application can now access the data through its own memory space. Buffer management techniques can optimize how data is cached and accessed in user space to reduce the number of read operations needed from the disk.

> *Similarly during writes, it is first updated in the application buffer, then copied to kernel buffer and then scheduled to be “flushed” to disk.*
> 

Of course, we can increase productivity with caching, but what if we need to process very large file on flight and what is more in several processes.

> **[NEED TO MENTION]** *Usually, the address space of the kernel buffer and application buffer need not be aligned i.e. it could be that the application buffer occupy bytes 0 to 4095 in the virtual memory and the kernel buffer occupy bytes 4096 to 8192 in virtual memory.*
> 

One of the ways we can speed up the process is to **avoid copying the actual pages from the kernel buffer to the application buffer**. This can be achieved by aligning the kernel and application buffer in the same address space in the virtual memory.

**Memory mapping technique is used to achieve this.**

![Untitled](MMAP%203d5205c31a294e24ad7bcbe70108dc08/Untitled%201.png)

Thus if we are updating a page from bytes 4096 to 8192, the same changes are visible to the kernel buffer without copying the changes. **The kernel can later schedule the “dirty page” to be flushed to the disk.**

> *Usually the write back to disk is asynchronous, thus when there are lots of writes per second, there is **risk of data loss**. We can make it synchronous by using “sync”, “fsync” or “msync” commands.*
> 

Basically, when we use mmap system call, next happens:

1. **`open()`**: Opens a file and returns a file descriptor, which is necessary for mapping the file to memory.
2. **`mmap()`**: Maps the file represented by the file descriptor into the process's virtual address space, allowing the file to be accessed through memory addresses rather than read/write system calls.
3. **`msync()`** (optional): Synchronizes changes made to the mapped memory with the physical file on disk. This call is used if updates need to be written back to the file system immediately, which is especially relevant for shared file mappings.
4. **`munmap()`**: Unmaps the previously mapped file from the process's address space, effectively closing the memory-mapped file and potentially freeing up resources.
5. **`close()`**:  Closes the file descriptor once all operations on the mapped file are complete, ensuring that all resources associated with the file descriptor are properly released.

**So, we can see that we got rid of multiple copying.**

### Long story short

Reading a file normally involves system I/O calls — fread (fwrite for writes). The OS will read the segment of the file request, cache the data in the kernel page cache and place a copy in the user space of the process. mmap avoids these expensive system calls. Data is copied from the file directly into user-mode. The application can read those memory addresses and the OS will serve pages (typically 4KB) of the file accordingly.

**The data you get is lazily downloading by pages if page fault occurs.**

![https://media3.giphy.com/media/L2XVXVQxqAYwkOVRXS/giphy.gif?cid=7941fdc6zwgwm2wlhbelw7xrvgizj93p7wi252v3batk27u3&ep=v1_gifs_search&rid=giphy.gif&ct=g](https://media3.giphy.com/media/L2XVXVQxqAYwkOVRXS/giphy.gif?cid=7941fdc6zwgwm2wlhbelw7xrvgizj93p7wi252v3batk27u3&ep=v1_gifs_search&rid=giphy.gif&ct=g)

---

## Examples 🤗

```python
mmap.mmap(file_obj.fileno(), length=0, access=mmap.ACCESS_READ)
```

`mmap` requires a [file descriptor](https://en.wikipedia.org/wiki/File_descriptor), which comes from the `fileno()` method of a regular file object. A file descriptor is an internal identifier, typically an [integer](https://realpython.com/python-data-types/#integers), that the operating system uses to keep track of open files.

The second argument to `mmap` is `length=0`. This is the length in bytes of the memory map. `0` is a special value indicating that the system should create a memory map large enough to hold the entire file.

Accesses:

- **`ACCESS_READ`** creates a read-only memory map.
- **`ACCESS_DEFAULT`** defaults to the mode specified in the optional `prot` argument, which is used for [memory protection](https://en.wikipedia.org/wiki/Memory_protection).
- **`ACCESS_WRITE`** and **`ACCESS_COPY`** are the two write modes

Another useful argument is `offset`, which can be a memory-saving technique. This instructs the `mmap` to create a memory map starting at a specified offset in the file.

### MMAP objects as strings

memory mapping transparently loads the file contents into memory as a string. So, once you open the file, you can perform lots of the same operations you use with strings, such as slicing:

```python
import mmap

def mmap_io(filename):
    with open(filename, mode="r", encoding="utf8") as file_obj:
        with mmap.mmap(file_obj.fileno(), length=0, access=mmap.ACCESS_READ) as mmap_obj:
            print(mmap_obj[10:20])
```

This code prints ten characters from `mmap_obj` to the screen and also reads those ten characters into physical memory. Again, the data is read lazily.

> `*mmap` operates on bytes, not strings.*
> 

### Search in mmap objects

- We can use find() and rfind() methods with mmap, because they are … ?
    
    strings
    

> *See speed_test.py for realisation.*
> 

File size - 14.4MB

Output:

```python
REGULAR [0.010178047999943374, 0.011886219999951209, 0.011391774000003352]; 
MMAP    [0.00010331399994356616, 0.00012932599997839134, 0.00011222400007682154]
```

### MMAP with regexp

> *See regexpression_speed_test.py for realisation*
> 

File size - 14.4MB

```python
REGULAR [1.1221689799999695, 1.113195633000032, 1.0711920119999832]; 
MMAP [1.077727030999995, 1.025518596999973, 0.9433542900001157]
```

### **Memory-Mapped Objects as Files**

> *See seek_speed_test.py for realisation*
> 

File size - 14.4MB

```python
REGULAR [0.011419835999959105, 0.011431377999997494, 0.010871354000073552]; 
MMAP [8.231199990405003e-05, 4.7556000026816037e-05, 4.373299998405855e-05]
```

### Write with mmap

Memory mapping is most useful for reading files, but you can also use it to write files. The `mmap` API for writing files is very similar to regular file I/O except that it will raise a `ValueError` exception if the file is empty at the time you create the `mmap` object.

Python’s `mmap` module doesn’t allow memory mapping of an empty file. This is reasonable because, conceptually, an empty memory-mapped file is just a buffer of memory, so no memory mapping object is needed.

Typically, memory mapping is used in read or read/write mode. For example, the following code demonstrates how to quickly read a file and modify only a portion of it:

```python
import mmap

def mmap_io_write(filename):
    with open(filename, mode="r+") as file_obj:
        with mmap.mmap(file_obj.fileno(), length=0, access=mmap.ACCESS_WRITE) as mmap_obj:
            mmap_obj[10:16] = b"python"
            mmap_obj.flush()
```

The changes written to `mmap_obj` are visible in the file on disk as well as in memory. The official Python documentation recommends always calling `flush()` to guarantee the data is written back to the disk.

### Search and replace text

> *See search_and_replace_speed_test.py for realisation*
> 

File size - 14.4MB

```python
REGULAR [0.04529506299968489, 0.03494316500018613, 0.03632182599994849]; 
MMAP [0.022807094999734545, 0.01905749699972148, 0.019124780000311148]
```

### **Sharing Data Between Processes With Python’s mmap**

We can also make mmap that doesn’t have physical representation, all need to do is to pass -1 as a file descriptor:

```python
import mmap

with mmap.mmap(-1, length=100, access=mmap.ACCESS_WRITE) as mmap_obj:
    mmap_obj[0:100] = b"a" * 100
    print(mmap_obj[0:100])
```

> ***We can use anonymous memory-mapped objects to exchange data between processes even though the processes have completely separate memory and stacks.***
> 

```python
import mmap

def sharing_with_mmap():
    BUF = mmap.mmap(-1, length=100, access=mmap.ACCESS_WRITE)

    pid = os.fork()
    if pid == 0:
        # Child process
        BUF[0:100] = b"a" * 100
    else:
        time.sleep(2)
        print(BUF[0:100])
```

Sharing memory with memory mapping has several advantages:

- Data doesn’t have to be copied between processes.
- The operating system handles the memory transparently.
- Data doesn’t have to be [pickled](https://realpython.com/python-pickle-module/) between processes, which saves CPU time.
- Hovewer, you may ask a question, why you don’t use multiprocessing package ?
    
    The `multiprocessing` module requires data passed between processes to support the pickle protocol, which `mmap` does not.
    
    ```python
    from multiprocessing import Process
    
    def modify(buf):
        buf[0:100] = b"xy" * 50
    
    if __name__ == "__main__":
        BUF = mmap.mmap(-1, length=100, access=mmap.ACCESS_WRITE)
        BUF[0:100] = b"a" * 100
        p = Process(target=modify, args=(BUF,))
        p.start()
        p.join()
        print(BUF[0:100])
    ```
    
    **So, this code will rase TypeError exception**
    

In Python ≥ 3.8, we can use `shared_memory` package for this purposes

```python
from multiprocessing import Process
from multiprocessing import shared_memory

def modify(buf_name):
    shm = shared_memory.SharedMemory(buf_name)
    shm.buf[0:50] = b"b" * 50
    shm.close()

if __name__ == "__main__":
    shm = shared_memory.SharedMemory(create=True, size=100)

    try:
        shm.buf[0:100] = b"a" * 100
        proc = Process(target=modify, args=(shm.name,))
        proc.start()
        proc.join()
        print(bytes(shm.buf[:100]))
    finally:
        shm.close()
        shm.unlink()
```

Under the hood, the `shared_memory` module uses each operating system’s unique API to create named memory maps for you.