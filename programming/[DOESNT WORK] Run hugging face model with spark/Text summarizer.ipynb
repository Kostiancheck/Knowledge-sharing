{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2023-10-04T14:40:27.923049Z",
     "start_time": "2023-10-04T14:40:25.547686Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Ich liebe Pizza!!!</s>\n"
     ]
    }
   ],
   "source": [
    "test_text = \"\"\"\n",
    "Translate to Germany: I love pizza!!!\n",
    "\"\"\"\n",
    "\n",
    "input_ids = tokenizer(test_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "outputs = model.generate(input_ids, max_new_tokens=1000)\n",
    "print(tokenizer.decode(outputs[0]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:42:39.253883Z",
     "start_time": "2023-10-04T14:42:39.141290Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-09-28T10:50:07.699721Z",
     "start_time": "2023-09-28T10:50:07.694375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "We describe a new algorithm, the k,ell-pebble game with colors, and use\n",
      "it obtain a characterization of the family of k,ell-sparse graphs and\n",
      "algorithmic solutions to a family of problems concerning tree decompositions of\n",
      "graphs. Special instances of sparse graphs appear in rigidity theory and have\n",
      "received increased attention in recent years. In particular, our colored\n",
      "pebbles generalize and strengthen the previous results of Lee and Streinu and\n",
      "give a new proof of the Tutte-Nash-Williams characterization of arboricity. We\n",
      "also present a new decomposition that certifies sparsity based on the\n",
      "k,ell-pebble game with colors. Our work also exposes connections between\n",
      "pebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and\n",
      "Westermann and Hendrickson\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "We describe a new algorithm, the k,ell-pebble game with colors, and use\n",
    "it obtain a characterization of the family of k,ell-sparse graphs and\n",
    "algorithmic solutions to a family of problems concerning tree decompositions of\n",
    "graphs. Special instances of sparse graphs appear in rigidity theory and have\n",
    "received increased attention in recent years. In particular, our colored\n",
    "pebbles generalize and strengthen the previous results of Lee and Streinu and\n",
    "give a new proof of the Tutte-Nash-Williams characterization of arboricity. We\n",
    "also present a new decomposition that certifies sparsity based on the\n",
    "k,ell-pebble game with colors. Our work also exposes connections between\n",
    "pebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and\n",
    "Westermann and Hendrickson\n",
    "\"\"\"\n",
    "\n",
    "print(text)\n",
    "\n",
    "summ_text = f\"Summarize text: {text}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-09-28T10:50:12.604832Z",
     "start_time": "2023-09-28T10:50:11.973554Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad>We present a new algorithm for a new k,ell-pebble game with\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(summ_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-09-28T10:51:12.491471Z",
     "start_time": "2023-09-28T10:51:08.909233Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "my_list = [{\"a\": 1, \"summ_text\": summ_text}]\n",
    "dataset = Dataset.from_list(my_list)\n",
    "\n",
    "\n",
    "def tokenization(example):\n",
    "    input_ids = tokenizer(example[\"summ_text\"], return_tensors=\"pt\").input_ids\n",
    "    outputs = model.generate(input_ids)\n",
    "    example[\"summary\"] = tokenizer.decode(outputs[0])\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def add_summ_promt(example):\n",
    "    example[\"summ_text\"] = 'Summarize text: ' + example[\"abstract\"]\n",
    "    return example\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T10:59:45.911839Z",
     "start_time": "2023-09-28T10:59:45.903580Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T18:43:25.445394Z",
     "start_time": "2023-09-27T18:43:08.735274Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3b2c685977426ba3059e536e478bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'text': 'Summarize text: \\nWe describe a new algorithm, the k,ell-pebble game with colors, and use\\nit obtain a characterization of the family of k,ell-sparse graphs and\\nalgorithmic solutions to a family of problems concerning tree decompositions of\\ngraphs. Special instances of sparse graphs appear in rigidity theory and have\\nreceived increased attention in recent years. In particular, our colored\\npebbles generalize and strengthen the previous results of Lee and Streinu and\\ngive a new proof of the Tutte-Nash-Williams characterization of arboricity. We\\nalso present a new decomposition that certifies sparsity based on the\\nk,ell-pebble game with colors. Our work also exposes connections between\\npebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and\\nWestermann and Hendrickson\\n', 'summary': '<pad>We present a new algorithm for a new k,ell-pebble game with'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf70fff467f64ef5b06a8f7f4a47125c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'text': 'Summarize text: \\nWe describe a new algorithm, the k,ell-pebble game with colors, and use\\nit obtain a characterization of the family of k,ell-sparse graphs and\\nalgorithmic solutions to a family of problems concerning tree decompositions of\\ngraphs. Special instances of sparse graphs appear in rigidity theory and have\\nreceived increased attention in recent years. In particular, our colored\\npebbles generalize and strengthen the previous results of Lee and Streinu and\\ngive a new proof of the Tutte-Nash-Williams characterization of arboricity. We\\nalso present a new decomposition that certifies sparsity based on the\\nk,ell-pebble game with colors. Our work also exposes connections between\\npebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and\\nWestermann and Hendrickson\\n', 'summary': '<pad>We present a new algorithm for a new k,ell-pebble game with'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8320414490544d783b10f3933d1151f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'text': 'Summarize text: \\nWe describe a new algorithm, the k,ell-pebble game with colors, and use\\nit obtain a characterization of the family of k,ell-sparse graphs and\\nalgorithmic solutions to a family of problems concerning tree decompositions of\\ngraphs. Special instances of sparse graphs appear in rigidity theory and have\\nreceived increased attention in recent years. In particular, our colored\\npebbles generalize and strengthen the previous results of Lee and Streinu and\\ngive a new proof of the Tutte-Nash-Williams characterization of arboricity. We\\nalso present a new decomposition that certifies sparsity based on the\\nk,ell-pebble game with colors. Our work also exposes connections between\\npebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and\\nWestermann and Hendrickson\\n', 'summary': '<pad>We present a new algorithm for a new k,ell-pebble game with'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0a3bea0be743cba362c131bab90598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'text': 'Summarize text: \\nWe describe a new algorithm, the k,ell-pebble game with colors, and use\\nit obtain a characterization of the family of k,ell-sparse graphs and\\nalgorithmic solutions to a family of problems concerning tree decompositions of\\ngraphs. Special instances of sparse graphs appear in rigidity theory and have\\nreceived increased attention in recent years. In particular, our colored\\npebbles generalize and strengthen the previous results of Lee and Streinu and\\ngive a new proof of the Tutte-Nash-Williams characterization of arboricity. We\\nalso present a new decomposition that certifies sparsity based on the\\nk,ell-pebble game with colors. Our work also exposes connections between\\npebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and\\nWestermann and Hendrickson\\n', 'summary': '<pad>We present a new algorithm for a new k,ell-pebble game with'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c65e62bb1b4237a52b35bd8c868f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'text': 'Summarize text: \\nWe describe a new algorithm, the k,ell-pebble game with colors, and use\\nit obtain a characterization of the family of k,ell-sparse graphs and\\nalgorithmic solutions to a family of problems concerning tree decompositions of\\ngraphs. Special instances of sparse graphs appear in rigidity theory and have\\nreceived increased attention in recent years. In particular, our colored\\npebbles generalize and strengthen the previous results of Lee and Streinu and\\ngive a new proof of the Tutte-Nash-Williams characterization of arboricity. We\\nalso present a new decomposition that certifies sparsity based on the\\nk,ell-pebble game with colors. Our work also exposes connections between\\npebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and\\nWestermann and Hendrickson\\n', 'summary': '<pad>We present a new algorithm for a new k,ell-pebble game with'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b26a10863d34ab2b644e5704d9f0816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'text': 'Summarize text: \\nWe describe a new algorithm, the k,ell-pebble game with colors, and use\\nit obtain a characterization of the family of k,ell-sparse graphs and\\nalgorithmic solutions to a family of problems concerning tree decompositions of\\ngraphs. Special instances of sparse graphs appear in rigidity theory and have\\nreceived increased attention in recent years. In particular, our colored\\npebbles generalize and strengthen the previous results of Lee and Streinu and\\ngive a new proof of the Tutte-Nash-Williams characterization of arboricity. We\\nalso present a new decomposition that certifies sparsity based on the\\nk,ell-pebble game with colors. Our work also exposes connections between\\npebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and\\nWestermann and Hendrickson\\n', 'summary': '<pad>We present a new algorithm for a new k,ell-pebble game with'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a45affc8834485ba2b13155fe29a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'text': 'Summarize text: \\nWe describe a new algorithm, the k,ell-pebble game with colors, and use\\nit obtain a characterization of the family of k,ell-sparse graphs and\\nalgorithmic solutions to a family of problems concerning tree decompositions of\\ngraphs. Special instances of sparse graphs appear in rigidity theory and have\\nreceived increased attention in recent years. In particular, our colored\\npebbles generalize and strengthen the previous results of Lee and Streinu and\\ngive a new proof of the Tutte-Nash-Williams characterization of arboricity. We\\nalso present a new decomposition that certifies sparsity based on the\\nk,ell-pebble game with colors. Our work also exposes connections between\\npebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and\\nWestermann and Hendrickson\\n', 'summary': '<pad>We present a new algorithm for a new k,ell-pebble game with'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3055d85ed97d4cf1bf85461815a07825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'text': 'Summarize text: \\nWe describe a new algorithm, the k,ell-pebble game with colors, and use\\nit obtain a characterization of the family of k,ell-sparse graphs and\\nalgorithmic solutions to a family of problems concerning tree decompositions of\\ngraphs. Special instances of sparse graphs appear in rigidity theory and have\\nreceived increased attention in recent years. In particular, our colored\\npebbles generalize and strengthen the previous results of Lee and Streinu and\\ngive a new proof of the Tutte-Nash-Williams characterization of arboricity. We\\nalso present a new decomposition that certifies sparsity based on the\\nk,ell-pebble game with colors. Our work also exposes connections between\\npebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and\\nWestermann and Hendrickson\\n', 'summary': '<pad>We present a new algorithm for a new k,ell-pebble game with'}\n",
      "2.03 s ± 141 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "dataset_proc = dataset.map(tokenization)\n",
    "print(dataset_proc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-09-28T11:06:07.574148Z",
     "start_time": "2023-09-28T11:06:06.874556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 101 ms, sys: 98.7 ms, total: 200 ms\n",
      "Wall time: 694 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "big_dataset = load_dataset('json', data_files='arxiv-metadata-oai-snapshot.json', split=\"train\") # streaming=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "subset = big_dataset.select(range(1000))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T11:09:21.688608Z",
     "start_time": "2023-09-28T11:09:21.680704Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.59 ms, sys: 1.69 ms, total: 7.29 ms\n",
      "Wall time: 5.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "subset = subset.map(add_summ_promt)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T11:09:22.882895Z",
     "start_time": "2023-09-28T11:09:22.873882Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "Map (num_proc=16):   0%|          | 0/1000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a3c396063bb64f2897b4a499197e97ca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.92 s, sys: 1.03 s, total: 6.95 s\n",
      "Wall time: 4min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "subset_proc = subset.map(tokenization, keep_in_memory=True, num_proc=16)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T11:18:31.425706Z",
     "start_time": "2023-09-28T11:13:33.622469Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "00ce78b1e12040c3afb733b4206eb574"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33min 34s, sys: 45.2 s, total: 34min 19s\n",
      "Wall time: 5min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "subset_proc = subset.map(tokenization, keep_in_memory=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T11:42:27.283539Z",
     "start_time": "2023-09-28T11:36:32.085820Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "subset_proc.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "subset_proc.to_json(\"processed_subset_dateset/\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Spark"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/28 15:14:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "      .master(\"local[*]\") \\\n",
    "      .appName(\"hugging_face_model\") \\\n",
    "      .getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T12:14:51.370768Z",
     "start_time": "2023-09-28T12:14:45.753174Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "oai_spark_dataset = (\n",
    "    spark\n",
    "    .read\n",
    "    .json(\"arxiv-metadata-oai-snapshot.json\")\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T12:16:04.037973Z",
     "start_time": "2023-09-28T12:15:49.613102Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- abstract: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- authors_parsed: array (nullable = true)\n",
      " |    |-- element: array (containsNull = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- comments: string (nullable = true)\n",
      " |-- doi: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- journal-ref: string (nullable = true)\n",
      " |-- license: string (nullable = true)\n",
      " |-- report-no: string (nullable = true)\n",
      " |-- submitter: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- update_date: string (nullable = true)\n",
      " |-- versions: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- created: string (nullable = true)\n",
      " |    |    |-- version: string (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+--------------------+-----------------+--------------------+--------------------+---------+--------------------+--------------------+--------------------+------------------+--------------------+-----------+--------------------+\n",
      "|            abstract|             authors|      authors_parsed|       categories|            comments|                 doi|       id|         journal-ref|             license|           report-no|         submitter|               title|update_date|            versions|\n",
      "+--------------------+--------------------+--------------------+-----------------+--------------------+--------------------+---------+--------------------+--------------------+--------------------+------------------+--------------------+-----------+--------------------+\n",
      "|  A fully differe...|C. Bal\\'azs, E. L...|[[Balázs, C., ], ...|           hep-ph|37 pages, 15 figu...|10.1103/PhysRevD....|0704.0001|Phys.Rev.D76:0130...|                NULL|    ANL-HEP-PR-07-12|    Pavel Nadolsky|Calculation of pr...| 2008-11-26|[{Mon, 2 Apr 2007...|\n",
      "|  We describe a n...|Ileana Streinu an...|[[Streinu, Ileana...|    math.CO cs.CG|To appear in Grap...|                NULL|0704.0002|                NULL|http://arxiv.org/...|                NULL|      Louis Theran|Sparsity-certifyi...| 2008-12-13|[{Sat, 31 Mar 200...|\n",
      "|  The evolution o...|         Hongjun Pan|  [[Pan, Hongjun, ]]|   physics.gen-ph| 23 pages, 3 figures|                NULL|0704.0003|                NULL|                NULL|                NULL|       Hongjun Pan|The evolution of ...| 2008-01-13|[{Sun, 1 Apr 2007...|\n",
      "|  We show that a ...|        David Callan| [[Callan, David, ]]|          math.CO|            11 pages|                NULL|0704.0004|                NULL|                NULL|                NULL|      David Callan|A determinant of ...| 2007-05-23|[{Sat, 31 Mar 200...|\n",
      "|  In this paper w...|Wael Abu-Shammala...|[[Abu-Shammala, W...|  math.CA math.FA|                NULL|                NULL|0704.0005|Illinois J. Math....|                NULL|                NULL|Alberto Torchinsky|From dyadic $\\Lam...| 2013-10-15|[{Mon, 2 Apr 2007...|\n",
      "|  We study the tw...|Y. H. Pong and C....|[[Pong, Y. H., ],...|cond-mat.mes-hall|6 pages, 4 figure...|10.1103/PhysRevA....|0704.0006|                NULL|                NULL|                NULL|      Yue Hin Pong|Bosonic character...| 2015-05-13|[{Sat, 31 Mar 200...|\n",
      "|  A rather non-st...|Alejandro Corichi...|[[Corichi, Alejan...|            gr-qc|16 pages, no figu...|10.1103/PhysRevD....|0704.0007|Phys.Rev.D76:0440...|                NULL|        IGPG-07/03-2| Alejandro Corichi|Polymer Quantum M...| 2008-11-26|[{Sat, 31 Mar 200...|\n",
      "|  A general formu...|     Damian C. Swift|[[Swift, Damian C...|cond-mat.mtrl-sci|   Minor corrections|   10.1063/1.2975338|0704.0008|Journal of Applie...|http://arxiv.org/...|LA-UR-07-2051, LL...|      Damian Swift|Numerical solutio...| 2009-02-05|[{Sat, 31 Mar 200...|\n",
      "|  We discuss the ...|Paul Harvey, Brun...|[[Harvey, Paul, ]...|         astro-ph|                NULL|      10.1086/518646|0704.0009|Astrophys.J.663:1...|                NULL|                NULL|       Paul Harvey|The Spitzer c2d S...| 2010-03-18|[{Mon, 2 Apr 2007...|\n",
      "|  Partial cubes a...|  Sergei Ovchinnikov|[[Ovchinnikov, Se...|          math.CO|36 pages, 17 figures|                NULL|0704.0010|                NULL|                NULL|                NULL|Sergei Ovchinnikov|Partial cubes: st...| 2007-05-23|[{Sat, 31 Mar 200...|\n",
      "|  In this paper w...|Clifton Cunningha...|[[Cunningham, Cli...|  math.NT math.AG|14 pages; title c...|                NULL|0704.0011|                NULL|http://arxiv.org/...|                NULL|Clifton Cunningham|Computing genus 2...| 2008-08-20|[{Sat, 31 Mar 200...|\n",
      "|  Recently, Bruin...|         Dohoon Choi|  [[Choi, Dohoon, ]]|          math.NT|                NULL|                NULL|0704.0012|                NULL|                NULL|                NULL|       Dohoon Choi|Distribution of i...| 2007-05-23|[{Sat, 31 Mar 200...|\n",
      "|  Serre obtained ...|Dohoon Choi and Y...|[[Choi, Dohoon, ]...|          math.NT|                NULL|                NULL|0704.0013|                NULL|                NULL|                NULL|       Dohoon Choi|$p$-adic Limit of...| 2008-05-26|[{Sat, 31 Mar 200...|\n",
      "|  In this article...|        Koichi Fujii| [[Fujii, Koichi, ]]|  math.CA math.AT|  18 pages, 1 figure|                NULL|0704.0014|                NULL|                NULL|                NULL|      Koichi Fujii|Iterated integral...| 2009-09-29|[{Sun, 1 Apr 2007...|\n",
      "|  The pure spinor...|     Christian Stahn|[[Stahn, Christia...|           hep-th|22 pages; signs a...|10.1088/1126-6708...|0704.0015|  JHEP 0705:034,2007|                NULL|                NULL|   Christian Stahn|Fermionic superst...| 2009-11-13|[{Mon, 2 Apr 2007...|\n",
      "|  In this work, w...|Chao-Hsi Chang, T...|[[Chang, Chao-Hsi...|           hep-ph|17 pages, 3 figur...|10.1088/0253-6102...|0704.0016|Commun.Theor.Phys...|                NULL|                NULL|           Li Tong|Lifetime of doubl...| 2008-12-18|[{Sat, 31 Mar 200...|\n",
      "|  Results from sp...|Nceba Mhlahlo, Da...|[[Mhlahlo, Nceba,...|         astro-ph|10 pages, 11 figu...|10.1111/j.1365-29...|0704.0017|Mon.Not.Roy.Astro...|                NULL|                NULL|     Nceba Mhlahlo|Spectroscopic Obs...| 2009-06-23|[{Sat, 31 Mar 200...|\n",
      "|  We give a presc...|  Andreas Gustavsson|[[Gustavsson, And...|           hep-th|20 pages, v2: an ...|                NULL|0704.0018|                NULL|                NULL|                NULL|Andreas Gustavsson|In quest of a gen...| 2007-05-23|[{Mon, 2 Apr 2007...|\n",
      "|  In this note we...|         Norio Konno|  [[Konno, Norio, ]]|  math.PR math.AG|6 pages, Journal-...|                NULL|0704.0019|RIMS Kokyuroku, N...|                NULL|                NULL|       Norio Konno|Approximation for...| 2007-06-23|[{Sat, 31 Mar 200...|\n",
      "|  The shape of th...|The BABAR Collabo...|[[The BABAR Colla...|           hep-ex|21 pages, 13 post...|10.1103/PhysRevD....|0704.0020|Phys.Rev.D76:0520...|                NULL|BABAR-PUB-07/015,...|   Patrick Roudeau|Measurement of th...| 2015-06-30|[{Sat, 31 Mar 200...|\n",
      "+--------------------+--------------------+--------------------+-----------------+--------------------+--------------------+---------+--------------------+--------------------+--------------------+------------------+--------------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:===============================================>         (24 + 5) / 29]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2326839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "oai_spark_dataset.printSchema()\n",
    "oai_spark_dataset.show(20)\n",
    "print(oai_spark_dataset.count())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T12:16:49.042087Z",
     "start_time": "2023-09-28T12:16:44.869843Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "tokenizer_br = spark.sparkContext.broadcast(tokenizer)\n",
    "model_br = spark.sparkContext.broadcast(model)\n",
    "\n",
    "def tokenization_spark(summ_text):\n",
    "    input_ids = tokenizer_br.value(summ_text, return_tensors=\"pt\").input_ids\n",
    "    outputs = model_br.generate(input_ids)\n",
    "    return tokenizer_br.value.decode(outputs[0])\n",
    "\n",
    "# Converting function to UDF\n",
    "tokenization_udf = udf(lambda t: tokenization_spark(t),StringType())\n",
    "\n",
    "summary = (oai_spark_dataset\n",
    " .withColumn(\"summ_text\", concat(lit('Summarize text: '), col(\"abstract\")))\n",
    " .withColumn(\"summary\", tokenization_udf(col(\"summ_text\")))\n",
    " )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T12:29:55.499994Z",
     "start_time": "2023-09-28T12:29:47.946736Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- abstract: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- authors_parsed: array (nullable = true)\n",
      " |    |-- element: array (containsNull = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- comments: string (nullable = true)\n",
      " |-- doi: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- journal-ref: string (nullable = true)\n",
      " |-- license: string (nullable = true)\n",
      " |-- report-no: string (nullable = true)\n",
      " |-- submitter: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- update_date: string (nullable = true)\n",
      " |-- versions: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- created: string (nullable = true)\n",
      " |    |    |-- version: string (nullable = true)\n",
      " |-- summ_text: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>               (0 + 12) / 29][Stage 14:>                 (0 + 0) / 1]\r"
     ]
    }
   ],
   "source": [
    "summary.printSchema()\n",
    "summary.show(20)\n",
    "print(summary.count())\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-09-28T12:30:22.207648Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "ERROR:root:KeyboardInterrupt while sending command.               (0 + 12) / 29]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/Users/kostiantynhorbach/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m<timed eval>:1\u001B[0m\n",
      "File \u001B[0;32m~/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/pyspark/sql/readwriter.py:1658\u001B[0m, in \u001B[0;36mDataFrameWriter.json\u001B[0;34m(self, path, mode, compression, dateFormat, timestampFormat, lineSep, encoding, ignoreNullFields)\u001B[0m\n\u001B[1;32m   1649\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode(mode)\n\u001B[1;32m   1650\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_opts(\n\u001B[1;32m   1651\u001B[0m     compression\u001B[38;5;241m=\u001B[39mcompression,\n\u001B[1;32m   1652\u001B[0m     dateFormat\u001B[38;5;241m=\u001B[39mdateFormat,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1656\u001B[0m     ignoreNullFields\u001B[38;5;241m=\u001B[39mignoreNullFields,\n\u001B[1;32m   1657\u001B[0m )\n\u001B[0;32m-> 1658\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jwrite\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjson\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1314\u001B[0m args_command, temp_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_args(\u001B[38;5;241m*\u001B[39margs)\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[0;32m-> 1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_command\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n\u001B[1;32m   1323\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
      "File \u001B[0;32m~/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/py4j/java_gateway.py:1038\u001B[0m, in \u001B[0;36mGatewayClient.send_command\u001B[0;34m(self, command, retry, binary)\u001B[0m\n\u001B[1;32m   1036\u001B[0m connection \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_connection()\n\u001B[1;32m   1037\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1038\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_command\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1039\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m binary:\n\u001B[1;32m   1040\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m response, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_connection_guard(connection)\n",
      "File \u001B[0;32m~/IdeaProjects/Knowledge-sharing/venv/lib/python3.9/site-packages/py4j/clientserver.py:511\u001B[0m, in \u001B[0;36mClientServerConnection.send_command\u001B[0;34m(self, command)\u001B[0m\n\u001B[1;32m    509\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    510\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 511\u001B[0m         answer \u001B[38;5;241m=\u001B[39m smart_decode(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m    512\u001B[0m         logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAnswer received: \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(answer))\n\u001B[1;32m    513\u001B[0m         \u001B[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001B[39;00m\n\u001B[1;32m    514\u001B[0m         \u001B[38;5;66;03m# answer before the socket raises an error.\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py:704\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    703\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 704\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    706\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "summary.limit(1000).write.json(\"spark_subset_test/\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T12:26:21.101799Z",
     "start_time": "2023-09-28T12:23:32.677390Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
